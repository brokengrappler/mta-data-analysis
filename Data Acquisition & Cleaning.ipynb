{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTA Analysis: Data Acquisition & Cleaning\n",
    "\n",
    "This analysis uses [publically available MTA Turnstile Data](http://web.mta.info/developers/turnstile.html) ranging from January 2018 until June 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define useful functions (maybe document and put this in .py file later?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp_to_mta_format(timestamp):\n",
    "    \n",
    "    year = str(timestamp.year)[2:4]\n",
    "    month = str(timestamp.month).zfill(2)\n",
    "    day = str(timestamp.day).zfill(2)\n",
    "    \n",
    "    date_mta_format = year + month + day\n",
    "    \n",
    "    return date_mta_format\n",
    "\n",
    "def create_raw_df(path):\n",
    "    '''\n",
    "    Input: subdirectory path containing data files\n",
    "    Output: One DF aggregating all data\n",
    "    '''\n",
    "    files = os.listdir(path)\n",
    "    raw_master_df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        df = pd.read_csv(os.path.join(path, file), index_col = 0)\n",
    "        raw_master_df = pd.concat([raw_master_df, df])\n",
    "\n",
    "    return raw_master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load [MTA Turnstile Data](http://web.mta.info/developers/turnstile.html) and combine into a single dataframe.\n",
    "_Note: The files already exist in the repository. This code block can be skipped over._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2015-05-02'\n",
    "months_of_interest = [5, 6]\n",
    "start_ts = pd.Timestamp(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2015-05-02 00:00:00...\n",
      "Downloading data for 2015-05-09 00:00:00...\n",
      "Downloading data for 2015-05-16 00:00:00...\n",
      "Downloading data for 2015-05-23 00:00:00...\n",
      "Downloading data for 2015-05-30 00:00:00...\n",
      "Downloading data for 2015-06-06 00:00:00...\n",
      "Downloading data for 2015-06-13 00:00:00...\n",
      "Downloading data for 2015-06-20 00:00:00...\n",
      "Downloading data for 2015-06-27 00:00:00...\n",
      "Downloading data for 2016-05-07 00:00:00...\n",
      "Downloading data for 2016-05-14 00:00:00...\n",
      "Downloading data for 2016-05-21 00:00:00...\n",
      "Downloading data for 2016-05-28 00:00:00...\n",
      "Downloading data for 2016-06-04 00:00:00...\n",
      "Downloading data for 2016-06-11 00:00:00...\n",
      "Downloading data for 2016-06-18 00:00:00...\n",
      "Downloading data for 2016-06-25 00:00:00...\n",
      "Downloading data for 2017-05-06 00:00:00...\n",
      "Downloading data for 2017-05-13 00:00:00...\n",
      "Downloading data for 2017-05-20 00:00:00...\n",
      "Downloading data for 2017-05-27 00:00:00...\n",
      "Downloading data for 2017-06-03 00:00:00...\n",
      "Downloading data for 2017-06-10 00:00:00...\n",
      "Downloading data for 2017-06-17 00:00:00...\n",
      "Downloading data for 2017-06-24 00:00:00...\n",
      "Downloading data for 2018-05-05 00:00:00...\n",
      "Downloading data for 2018-05-12 00:00:00...\n",
      "Downloading data for 2018-05-19 00:00:00...\n",
      "Downloading data for 2018-05-26 00:00:00...\n",
      "Downloading data for 2018-06-02 00:00:00...\n",
      "Downloading data for 2018-06-09 00:00:00...\n",
      "Downloading data for 2018-06-16 00:00:00...\n",
      "Downloading data for 2018-06-23 00:00:00...\n",
      "Downloading data for 2018-06-30 00:00:00...\n",
      "Downloading data for 2019-05-04 00:00:00...\n",
      "Downloading data for 2019-05-11 00:00:00...\n",
      "Downloading data for 2019-05-18 00:00:00...\n",
      "Downloading data for 2019-05-25 00:00:00...\n",
      "Downloading data for 2019-06-01 00:00:00...\n",
      "Downloading data for 2019-06-08 00:00:00...\n",
      "Downloading data for 2019-06-15 00:00:00...\n",
      "Downloading data for 2019-06-22 00:00:00...\n",
      "Downloading data for 2019-06-29 00:00:00...\n",
      "Downloading data for 2020-05-02 00:00:00...\n",
      "Downloading data for 2020-05-09 00:00:00...\n",
      "Downloading data for 2020-05-16 00:00:00...\n",
      "Downloading data for 2020-05-23 00:00:00...\n",
      "Downloading data for 2020-05-30 00:00:00...\n",
      "Downloading data for 2020-06-06 00:00:00...\n",
      "Downloading data for 2020-06-13 00:00:00...\n",
      "Downloading data for 2020-06-20 00:00:00...\n",
      "Downloading data for 2020-06-27 00:00:00...\n"
     ]
    }
   ],
   "source": [
    "current_timestamp = start_ts\n",
    "is_date_valid = True\n",
    "raw_master_df = pd.DataFrame()\n",
    "while is_date_valid:\n",
    "    if current_timestamp.month not in months_of_interest:\n",
    "        current_timestamp += pd.DateOffset(days=7)\n",
    "        continue\n",
    "    \n",
    "    print(f'Downloading data for {current_timestamp}...')\n",
    "    date_formatted = convert_timestamp_to_mta_format(current_timestamp)\n",
    "    \n",
    "    # load data and write to csv\n",
    "    url = f'http://web.mta.info/developers/data/nyct/turnstile/turnstile_{date_formatted}.txt'\n",
    "    df_turnstile_data = pd.read_csv(url)\n",
    "    raw_master_df = pd.concat([raw_master_df, df_turnstile_data])\n",
    "    \n",
    "    # add 7 days to get next file. if resulting date is later than today, then stop loop\n",
    "    current_timestamp += pd.DateOffset(days=7)\n",
    "    if current_timestamp > pd.to_datetime(\"now\"):\n",
    "        is_date_valid = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Combine CSVs into a single .pkl to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_master_df.to_pickle('processed_data/raw_mta_turnstile_data_mayjune_20152020.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Clean the data set.\n",
    "- change datatypes of columns\n",
    "- look for N/As\n",
    "- high level summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/25/2015</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5106770</td>\n",
       "      <td>1729635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/25/2015</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5106810</td>\n",
       "      <td>1729649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/25/2015</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5106835</td>\n",
       "      <td>1729680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/25/2015</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5106961</td>\n",
       "      <td>1729784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>LEXINGTON AVE</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>04/25/2015</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5107250</td>\n",
       "      <td>1729858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP        STATION LINENAME DIVISION        DATE  \\\n",
       "0  A002  R051  02-00-00  LEXINGTON AVE   NQR456      BMT  04/25/2015   \n",
       "1  A002  R051  02-00-00  LEXINGTON AVE   NQR456      BMT  04/25/2015   \n",
       "2  A002  R051  02-00-00  LEXINGTON AVE   NQR456      BMT  04/25/2015   \n",
       "3  A002  R051  02-00-00  LEXINGTON AVE   NQR456      BMT  04/25/2015   \n",
       "4  A002  R051  02-00-00  LEXINGTON AVE   NQR456      BMT  04/25/2015   \n",
       "\n",
       "       TIME     DESC  ENTRIES  \\\n",
       "0  00:00:00  REGULAR  5106770   \n",
       "1  04:00:00  REGULAR  5106810   \n",
       "2  08:00:00  REGULAR  5106835   \n",
       "3  12:00:00  REGULAR  5106961   \n",
       "4  16:00:00  REGULAR  5107250   \n",
       "\n",
       "   EXITS                                                                 \n",
       "0                                            1729635                     \n",
       "1                                            1729649                     \n",
       "2                                            1729680                     \n",
       "3                                            1729784                     \n",
       "4                                            1729858                     "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mta_raw = pd.read_pickle('processed_data/raw_mta_turnstile_data_mayjune_20152020.pkl')\n",
    "df_mta_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create a cleaned .pkl for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
